# Chunking Implementation

This document details the implementation of the document chunking pipeline for PDF and Markdown files.

## Overview

The chunking system converts uploaded documents into uniform text chunks suitable for embedding and retrieval. It runs entirely in the browser (or via web workers) to maintain the "local-first" architecture.

## 1. Database Schema

We evolved the schema to support granular chunks and their embeddings.

**File:** `src/db/schema.ts`

### `document_chunks`
Replaces the old `doc_text` table.
- **id**: Text hash of `docId + pageNumber + chunkIndex`.
- **docId**: Foreign key to `documents`.
- **docType**: "markdown" or "pdf".
- **pageNumber**: 1-based page index (always 1 for Markdown).
- **chunkIndex**: 0-based index of the chunk within the document.
- **headingPath**: (Optional) Hierarchical context.
- **text**: The actual chunk content.
- **embedded**: Boolean flag indicating if embeddings have been generated.

### `chunk_embeddings`
Replaces the old `embeddings` table.
- **chunkId**: Foreign key to `document_chunks`.
- **embeddingModel**: Identifier for the model used (e.g., "xenova/all-MiniLM-L6-v2").
- **embedding**: The vector data (768 dimensions).

## 2. Chunking Logic

**File:** `src/lib/chunking.ts`

We use LangChain libraries for robust text splitting.

### Markdown
- **Loader**: Reads the `Blob` as text.
- **Splitter**: `MarkdownTextSplitter` (from `@langchain/textsplitters`).
- **Settings**: `chunkSize: 1000`, `chunkOverlap: 150`.
- **Metadata**: Maps chunks to "Page 1".

### PDF
- **Loader**: `WebPDFLoader` (from `@langchain/community/document_loaders/web/pdf`), which uses `pdfjs-dist` under the hood.
- **Strategy**: Loads the PDF page-by-page.
- **Splitter**: `RecursiveCharacterTextSplitter` applied per page.
- **Settings**: `chunkSize: 1000`, `chunkOverlap: 150`.
- **Progress**: Emits progress events for both page loading and splitting.

## 3. Storage Layer

**File:** `src/lib/doc-storage.ts`

The storage logic is split into two distinct phases:

1.  **`saveDocument`**:
    *   Handles the raw file upload.
    *   Writes the binary data to PostgreSQL Large Objects (`lo_create`, `lowrite`).
    *   Creates the entry in the `documents` table.
    *   Returns the `docId`.

2.  **`saveChunks`**:
    *   Accepts the array of chunk objects generated by the splitter.
    *   Runs a transaction to delete old chunks (if any) and insert new ones into `document_chunks`.

## 4. UI Integration

**File:** `src/providers/document-upload.tsx`

The `DocumentUploadProvider` orchestrates the entire flow:

1.  **Upload Phase**: Calls `saveDocument`. Updates progress bar (0-50%).
2.  **Chunking Phase**:
    *   Determines file type.
    *   Calls `processPdf` or `processMarkdown`.
    *   Updates progress bar (50-100%) based on pages processed.
3.  **Save Phase**: Calls `saveChunks` to persist the results.
4.  **Completion**: Marks status as `success`.

## 5. Build Configuration

**File:** `vite.config.ts` & `src/lib/polyfills/node-module.ts`

To support LangChain's browser builds (which sometimes reference Node.js built-ins) in a Vite environment:
- Added a polyfill for `node:module` that throws an error if `require` is used.
- Configured a Vite alias to redirect `node:module` imports to this polyfill.
- Added `pdfjs-dist` to dependencies.

## Usage

The system automatically triggers when a user uploads a file via the `useDocumentUpload` hook. No manual intervention is needed. The UI reflects the state changes from "Uploading" to "Chunking" to "Success".
